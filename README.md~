# Delay-embedding Lorenz_example
This repository provide the source codes in /src for conducting delay embedding of a time series from a dynamical system, conducting diffusion maps dimensionality reduction, and verifying the geometrical identification. Together with the code is the simple of Lorenz attractor in /example_Lorenz, which can serve as the first example to verfify the validity of the codes.

## Lorenz attractor generation
Lorenz attractor is the 3 dimensional dynamical system generating from differential equation sets:
<p align="center">
<a href="https://www.codecogs.com/eqnedit.php?latex=\\&space;\frac{dx}{dt}=\sigma(y-x)\\&space;\frac{dy}{dt}=x(\rho-z)-y\\&space;\frac{dz}{dt}=xy-\beta&space;z\\" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\\&space;\frac{dx}{dt}=\sigma(y-x)\\&space;\frac{dy}{dt}=x(\rho-z)-y\\&space;\frac{dz}{dt}=xy-\beta&space;z\\" title="\\ \frac{dx}{dt}=\sigma(y-x)\\ \frac{dy}{dt}=x(\rho-z)-y\\ \frac{dz}{dt}=xy-\beta z\\" /></a>
</p>


A 20581 <img src="https://latex.codecogs.com/gif.latex?\times"> 3 dimensional vector will be generated using `lorenz_generating.m` in matlab

```bash
[X] = lorenz_generating(28,10,8/3,[0 1 1.05],[0 100],0.000001)

Lorenz_full = X
```

The Lorenz attractor is shown in Fig.1. Because 20581 points are slight too much, so we decide to evenly subsample 2000 points out from it, and generate a sparse version of the Lorenz attractor `Lorenz_sparse.mat`, we plot the full version `Lorenz_pull.mat` and the sparse version `Lorenz_sparse.mat` together as shown in Fig.1, these can be done using matlab script `Plot_dmap.m`:

```bash
Plot_dmap
```

<p align="center">
	<img src="example_Lorenz/Lorenz.png" width="600" height="400">
</p>
<p align="center">
	<em>Fig.1</em>
</p>

Refer to code provied by Moiseev Igor: https://www.mathworks.com/matlabcentral/fileexchange/30066-lorenz-attaractor-plot?focused=5176856&tab=function

## Delay time and delay dimension

We pretend to slect the x component from Lorenz attractor to perform delay embedding, when doing delay embedding, good delay time <img src="https://latex.codecogs.com/gif.latex?\tau"> and delay dimension D will be important, we use 'mutual information' (MI) to identify good delay time, and 'false nearest neighbour counting' to find good delay dimension. Good delay time can be the time at which MI drops to the first minima, applying `MI.m` to full version, we obtain the plot shown in Fig.2 top letf, which shows that <img src="https://latex.codecogs.com/gif.latex?\tau"> = 50 is a good delay time, but apply `MI.m` to the sparse version, it tells that <img src="https://latex.codecogs.com/gif.latex?\tau"> = 5 is a good delay time, as shown in the righ top panel in Fig.2, we will use <img src="https://latex.codecogs.com/gif.latex?\tau"> = 5.

We pick out x component of the sparse Lorenz attract as O:
```bash
O =  Lorenz_sparse(:,1)
```
and apply `MI.m` to O to generate MI plot, during which we select the number of bins to be 5, and maximum examine delay time to be 20:
```bash
MI(O)
```

As to good delay dimension, we use E1 measurement in 'false nearest neighbor' method, good delay dimension D is the dimension at which E1 mesurement reaches plateau and approaches 1.0. As shown in the bottom panel in Fig.2, the good dimension for Lorenz attractor is about 3.

```bash
FNN(O)
```
then set the maximum dimension to exam to be 10, with delay time to be 5.

<p align="center">
<img src="example_Lorenz/MI_full.png" width="400" height="300">
<img src="example_Lorenz/MI_sparse.png" width="400" height="300">
<img src="example_Lorenz/FNN.png" width="400" height="300">
</p>
<p align="center">
	<em>Fig.2</em>
</p>

For more about mutual information, refer to this article:  
https://doi.org/10.1103/PhysRevA.33.1134  
and https://doi.org/10.1016/S0167-2789(97)00118-8 for nearest neighbor.

## Dimensionality reduction of Lorenz attractor

Diffusion maps manifold learning technique could be applied to the Lorenz attractor:

```bash
dMap(5,20,0,Lorenz_sparse)
```

The eigenvalue spectrum in the top panel of Fig.3 tells us that the effective dimensionality of the Lorenz attractor is 2, since there is a clear spectrum gap between eigenvalue index 3 and 4, and eigenvector 1 corresponds to the trivial mode. The low dimensional embedding of the Lorenz attractor is spanned by <img src="https://latex.codecogs.com/gif.latex?\Psi_2"> and <img src="https://latex.codecogs.com/gif.latex?\Psi_3"> shown in the lower panel of Fig.3.

<p align="center">
<img src="example_Lorenz/Lorenz_spectrum.png" width="600" height="400">
<img src="example_Lorenz/Lorenz_dmap.png" width="600" height="400">
</p>
<p align="center">
	<em>Fig.3</em>
</p>

For more about diffusion maps, refer to these papers:  
https://doi.org/10.1073/pnas.0500334102  
https://doi.org/10.1137/070696325

## Delay embedding of Lorenz attractor

Given a time series observation <img src="https://latex.codecogs.com/gif.latex?X(t)"> from a dynamical system, the equivalent attractor can be reconstructed using delay embedding: 

<p align="center">
<a href="https://www.codecogs.com/eqnedit.php?latex=Y(t)&space;=&space;[X(t),X(t-\tau),X(t-2\tau),\cdots,X(t-(D-1)\tau)]" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Y(t)&space;=&space;[X(t),X(t-\tau),X(t-2\tau),\cdots,X(t-(D-1)\tau)]" title="Y(t) = [X(t),X(t-\tau),X(t-2\tau),\cdots,X(t-(D-1)\tau)]" /></a>
</p>


In the previous steps, we have find the good delay time and delay dimension for `Lorenz_sparse` to be 5 and 3, we can then construct the reconstructed delayed attractor using its x component:

```bash
RCT(O)
```

this will return us a 1990 <img src="https://latex.codecogs.com/gif.latex?\times"> 3 dimensional matrix `EBD.mat`, the reconstructed 3D attractor is shown in Fig.4.

<p align="center">
<img src="example_Lorenz/Lorenz_delayed.png" width="600" height="400">
</p>
<p align="center">
	<em>Fig.4</em>
</p>

Reference: https://doi.org/10.1016/0167-2789(86)90031-X

## Jacobian determinante

A map  <img src="https://latex.codecogs.com/gif.latex?\Theta"> which map manifold M to  <img src="https://latex.codecogs.com/gif.latex?\Theta(M)"> is diffeomorphic if the determinte of the Jacobian matrix is single signed, the Jacobian matrix is defined as the following:

<p align="center">
<img src="figures/detJ.png" width="500" height="200">
<img src="figures/detJ1.png" width="600" height="100">
</p>

Takens' embedding theorem says that the reconsturcted attractor and the original one should be diffeomorphic, the reconstructed 3-D Lorenz attractor in Fig.4 should be geometrical identical to the one in Fig.1, we could use 'meshless' method to compute the determinante of the mapping between these to attractors:

```bash
>> meshless_jacobian_3d;
```

This will return us the detJ computed for each point shown in the 3D version and temporal order, and are shown in Fig.5, we find that detJ for almost all point are single signed, means that the two attractor are geometrical identical to each other.

<p align="center">
<img src="example_Lorenz/Lorenz_detJ.png" width="600" height="400">
<img src="example_Lorenz/detJ_1D.png" width="600" height="400">
</p>
<p align="center">
	<em>Fig.5</em>
</p>
